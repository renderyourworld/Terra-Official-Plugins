apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: "{{ .Values.name }}"
  annotations:
    # comma separated list of users that can access this workstation as read only.
    juno-innovations.com/shared: "none"
    juno-innovations.com/kuiper-state: "{{ .Values._kuiper }}"
  labels:
    juno-innovations.com/app: "polaris"
    juno-innovations.com/workstation: "{{ .Values.name }}"
    juno-innovations.com/user: "{{ .Values.user }}"
    juno-innovations.com/session: "{{ .Values.session }}"


spec:
  replicas: 1

  selector:
    matchLabels:
      juno-innovations.com/workstation: "{{ .Values.name }}"

  template:
    metadata:
      labels:
        juno-innovations.com/app: polaris
        juno-innovations.com/user: "{{ .Values.user }}"
        juno-innovations.com/workstation: "{{ .Values.name }}"
      annotations:
        # This will block the cluster autoscaler from evicting this pod in the case
        # it can move to a cheaper instance. This does come at a cost, but ideally
        # this should stop from a workstation getting ripped out from under existing users.
        cluster-autoscaler.kubernetes.io/safe-to-evict: "false"

    spec:
      automountServiceAccountToken: false
      hostname: "{{ .Values.name }}"

      # workstation nodes will require juno-innovations.com/workstation: "true"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: juno-innovations.com/workstation
                    operator: In
                    values:
                      - "true"
                  {{- if .Values.selector }}
                  {{- range .Values.selector }}
                  - key: {{ .key | quote }}
                    operator: In
                    values:
                      - {{ .value | quote }}
                  {{- end }}
                  {{- end }}

      # allow for this pod to work on nodes reserved for workstations
      tolerations:
        - key: "juno-innovations.com/workstation"
          operator: "Exists"
          effect: "NoSchedule"

      {{- if .Values.gpu }}
      runtimeClassName: nvidia
      {{- end }}

      {{- if .Values.pullSecret }}
      imagePullSecrets:
        - name: "{{ .Values.pullSecret }}"
      {{- end }}

      containers:
        - name: webtop
          imagePullPolicy: IfNotPresent
          image: "{{ .Values.registry }}/{{ .Values.repo }}:{{ .Values.tag }}"
          resources:
            requests:
              memory: "{{ .Values.memory }}"
              cpu: "{{ .Values.cpu }}"
            # gotmpl's or is a function taking 2 args - this is "X or Y or Z" translated to python
            {{- if or (or .Values.gpu .Values.memoryLimit) .Values.cpuLimit }}
            limits:
            {{- if .Values.gpu }}
              nvidia.com/gpu: "1"
            {{- end }}
            {{- if .Values.cpuLimit }}
              cpu: "{{ .Values.cpuLimit }}"
            {{- end }}
            {{- if .Values.memoryLimit }}
              memory: "{{ .Values.memoryLimit }}"
            {{- end }}
            {{- end }}
{{/*          startupProbe:*/}}
{{/*            httpGet:*/}}
{{/*              path: "/polaris/{{ .Values.name }}/"*/}}
{{/*              port: 3000*/}}
{{/*            initialDelaySeconds: 2 # webtop boots very fast*/}}
{{/*            failureThreshold: 60  # start up totals 2 * 60 = 2 mins*/}}
{{/*            periodSeconds: 2*/}}
{{/*          livenessProbe:*/}}
{{/*            httpGet:*/}}
{{/*              path: "/polaris/{{ .Values.name }}/"*/}}
{{/*              port: 3000*/}}
{{/*            failureThreshold: 24*/}}
{{/*            periodSeconds: 5*/}}
          ports:
            - containerPort: 3001
              name: viewer
          env:
            - name: JUNO_WORKSTATION
              value: "{{ .Values.name }}"
            - name: JUNO_PROJECT
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: PUID
              value: "{{ .Values.puid }}"
            - name: PGID
              value: "{{ .Values.guid }}"
            - name: SUBFOLDER
              value: "/polaris/{{ .Values.name }}/"
            - name: START_DOCKER
              value: "false"
            {{- range .Values.env }}
            - name: {{ .name | quote }}
              value: {{ .value | quote }}
            {{- end }}
          volumeMounts:
            - mountPath: /dev/shm
              name: dshm
            {{- if .Values.volumeMounts }}
            {{- toYaml .Values.volumeMounts | nindent 12 }}
            {{- end }}
            {{- if .Values.plugins }}
            {{- range .Values.plugins }}
            - name: {{ .name | quote }}
              subPath: {{ .file | quote }}
              mountPath: "/etc/helios/init.d/{{ .name }}/{{ .file }}"
            {{- end }}
            {{- end }}
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
        {{- if .Values.volumeMounts }}
        {{- toYaml .Values.volumes | nindent 8 }}
        {{- end }}
        {{- if .Values.plugins }}
        {{- range .Values.plugins }}
        - name: {{ .name | quote }}
          configMap:
            name: {{ .config | quote }}
            defaultMode: 0777
        {{- end }}
        {{- end }}
